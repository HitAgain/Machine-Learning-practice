Boost
“装袋”（bagging）和“提升”（boost）是构建组合模型的两种最主要的方法，所谓的组合模型是由多个基本模型构成的模型，组合模型的预测效果往往比任意一个基本模型的效果都要好。

装袋：每个基本模型由从总体样本中随机抽样得到的不同数据集进行训练得到，通过重抽样得到不同训练数据集的过程称为装袋。

提升：每个基本模型训练时的数据集采用不同权重，针对上一个基本模型分类错误的样本增加权重，使得新的模型重点关注误分类样本



AdaBoost是AdaptiveBoost的缩写，表明该算法是具有适应性的提升算法，自适应体现在 对数据分布的自动改变 加强犯错数据的比例

算法的步骤如下：
1）给每个训练样本（ x1,x2,….,xN ）分配权重，初始权重 w1 均为1/N
2）针对带有权值的样本进行训练，得到模型 Gm （初始模型为G1）
3）计算模型 Gm 的误分率 em
4）计算模型 Gm 的系数 αm=0.5log[(1−em)/em]
5）根据误分率e和当前权重向量 wm 更新权重向量 wm+1
6）计算组合模型 f(x)=∑Mm=1αmGm(xi) 的误分率
7）当组合模型的误分率或迭代次数低于一定阈值，停止迭代；否则，回到步骤2）

在scikit-learn实现了两种AdaBoost分类算法，即SAMME和SAMME.R，
SAMME就是原理篇介绍到的AdaBoost算法，指Discrete AdaBoost
SAMME.R指Real AdaBoost，返回值不再是离散的类型，而是一个表示概率的实数值，算法流程见后文
两者的主要区别是弱分类器权重的度量，SAMME使用了分类效果作为弱分类器权重，SAMME.R使用了预测概率作为弱分类器权重。
SAMME.R的迭代一般比SAMME快，默认算法是SAMME.R。因此，base_estimator必须使用支持概率预测的分类器。